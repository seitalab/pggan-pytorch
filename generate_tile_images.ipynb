{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gen_R3_T155.pth.tar', 'gen_R3_T160.pth.tar', 'gen_R3_T165.pth.tar', 'gen_R3_T170.pth.tar', 'gen_R3_T175.pth.tar', 'gen_R3_T180.pth.tar', 'gen_R3_T185.pth.tar', 'gen_R3_T190.pth.tar', 'gen_R3_T195.pth.tar', 'gen_R3_T200.pth.tar', 'gen_R4_T255.pth.tar', 'gen_R4_T260.pth.tar', 'gen_R4_T265.pth.tar', 'gen_R4_T270.pth.tar', 'gen_R4_T275.pth.tar', 'gen_R4_T280.pth.tar', 'gen_R4_T285.pth.tar', 'gen_R4_T290.pth.tar', 'gen_R4_T295.pth.tar', 'gen_R4_T300.pth.tar', 'gen_R5_T355.pth.tar', 'gen_R5_T360.pth.tar', 'gen_R5_T365.pth.tar', 'gen_R5_T370.pth.tar', 'gen_R5_T375.pth.tar', 'gen_R5_T380.pth.tar', 'gen_R5_T385.pth.tar', 'gen_R5_T390.pth.tar', 'gen_R5_T395.pth.tar', 'gen_R5_T400.pth.tar', 'gen_R6_T455.pth.tar', 'gen_R6_T460.pth.tar', 'gen_R6_T465.pth.tar', 'gen_R6_T470.pth.tar', 'gen_R6_T475.pth.tar', 'gen_R6_T480.pth.tar', 'gen_R6_T485.pth.tar', 'gen_R6_T490.pth.tar', 'gen_R6_T495.pth.tar', 'gen_R6_T500.pth.tar', 'gen_R7_T555.pth.tar', 'gen_R7_T560.pth.tar', 'gen_R7_T565.pth.tar', 'gen_R7_T570.pth.tar', 'gen_R7_T575.pth.tar', 'gen_R7_T580.pth.tar', 'gen_R7_T585.pth.tar', 'gen_R7_T590.pth.tar', 'gen_R7_T595.pth.tar', 'gen_R7_T600.pth.tar', 'gen_R8_T655.pth.tar', 'gen_R8_T660.pth.tar', 'gen_R8_T665.pth.tar', 'gen_R8_T670.pth.tar', 'gen_R8_T675.pth.tar', 'gen_R8_T680.pth.tar', 'gen_R8_T685.pth.tar', 'gen_R8_T690.pth.tar', 'gen_R8_T695.pth.tar', 'gen_R8_T700.pth.tar', 'gen_R9_T755.pth.tar', 'gen_R9_T760.pth.tar', 'gen_R9_T765.pth.tar', 'gen_R9_T770.pth.tar', 'gen_R9_T775.pth.tar', 'gen_R9_T780.pth.tar', 'gen_R9_T785.pth.tar', 'gen_R9_T790.pth.tar', 'gen_R9_T795.pth.tar', 'gen_R9_T800.pth.tar', 'gen_R9_T805.pth.tar', 'gen_R9_T810.pth.tar', 'gen_R9_T815.pth.tar', 'gen_R9_T820.pth.tar', 'gen_R9_T825.pth.tar', 'gen_R9_T830.pth.tar', 'gen_R9_T835.pth.tar', 'gen_R9_T840.pth.tar', 'gen_R9_T845.pth.tar', 'gen_R9_T850.pth.tar', 'gen_R9_T855.pth.tar', 'gen_R9_T860.pth.tar', 'gen_R9_T865.pth.tar', 'gen_R9_T870.pth.tar', 'gen_R9_T875.pth.tar', 'gen_R9_T880.pth.tar', 'gen_R9_T885.pth.tar', 'gen_R9_T890.pth.tar', 'gen_R9_T895.pth.tar', 'gen_R9_T900.pth.tar', 'gen_R9_T905.pth.tar', 'gen_R9_T910.pth.tar', 'gen_R9_T915.pth.tar', 'gen_R9_T920.pth.tar', 'gen_R9_T925.pth.tar', 'gen_R9_T930.pth.tar', 'gen_R9_T935.pth.tar', 'gen_R9_T940.pth.tar', 'gen_R9_T945.pth.tar', 'gen_R9_T950.pth.tar', 'gen_R9_T955.pth.tar', 'gen_R9_T960.pth.tar', 'gen_R9_T965.pth.tar', 'gen_R9_T970.pth.tar', 'gen_R9_T975.pth.tar', 'gen_R9_T980.pth.tar', 'gen_R9_T985.pth.tar', 'gen_R9_T990.pth.tar', 'gen_R9_T995.pth.tar', 'gen_R9_T1000.pth.tar', 'gen_R9_T1005.pth.tar', 'gen_R9_T1010.pth.tar', 'gen_R9_T1015.pth.tar', 'gen_R9_T1020.pth.tar', 'gen_R9_T1025.pth.tar', 'gen_R9_T1030.pth.tar', 'gen_R9_T1035.pth.tar', 'gen_R9_T1040.pth.tar', 'gen_R9_T1045.pth.tar', 'gen_R9_T1050.pth.tar', 'gen_R9_T1055.pth.tar', 'gen_R9_T1060.pth.tar', 'gen_R9_T1065.pth.tar', 'gen_R9_T1070.pth.tar', 'gen_R9_T1075.pth.tar', 'gen_R9_T1080.pth.tar', 'gen_R9_T1085.pth.tar', 'gen_R9_T1090.pth.tar', 'gen_R9_T1095.pth.tar', 'gen_R9_T1100.pth.tar', 'gen_R9_T1105.pth.tar', 'gen_R9_T1110.pth.tar', 'gen_R9_T1115.pth.tar', 'gen_R9_T1120.pth.tar', 'gen_R9_T1125.pth.tar', 'gen_R9_T1130.pth.tar', 'gen_R9_T1135.pth.tar', 'gen_R9_T1140.pth.tar', 'gen_R9_T1145.pth.tar', 'gen_R9_T1150.pth.tar', 'gen_R9_T1155.pth.tar', 'gen_R9_T1160.pth.tar', 'gen_R9_T1165.pth.tar', 'gen_R9_T1170.pth.tar', 'gen_R9_T1175.pth.tar', 'gen_R9_T1180.pth.tar', 'gen_R9_T1185.pth.tar', 'gen_R9_T1190.pth.tar', 'gen_R9_T1195.pth.tar', 'gen_R9_T1200.pth.tar', 'gen_R9_T1205.pth.tar', 'gen_R9_T1210.pth.tar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tacchan7412/Developer/pggan-pytorch/custom_layers.py:104: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if initializer == 'kaiming':    kaiming_normal(self.conv.weight, a=calculate_gain('conv2d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "growing network[4x4 to 8x8]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tacchan7412/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "growing network[8x8 to 16x16]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[16x16 to 32x32]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[32x32 to 64x64]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[64x64 to 128x128]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[128x128 to 256x256]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[256x256 to 512x512]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-90871acf0f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0msave_tile_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-90871acf0f1f>\u001b[0m in \u001b[0;36msave_tile_images\u001b[0;34m(resl, images, save_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     grid = make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n\u001b[0;32m--> 101\u001b[0;31m                      normalize=normalize, range=range, scale_each=scale_each)\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36mmake_grid\u001b[0;34m(tensor, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import network as net\n",
    "from config import config\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import utils as vutils\n",
    "import random\n",
    "\n",
    "seed = 7412\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def save_tile_images(resl, images, save_path):\n",
    "    images = images.detach().cpu()\n",
    "    image_size = 2**resl\n",
    "    vutils.save_image(images, save_path, nrow=10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_48_14'\n",
    "# root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_48_59'\n",
    "#root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_49_29'\n",
    "root = '../storage/PGGAN/results/emarie_rose/2019_10_10_13_34_02'\n",
    "\n",
    "model_root = os.path.join(root, 'models')\n",
    "save_root = os.path.join(root, 'tile_images')\n",
    "\n",
    "model_list = os.listdir(model_root)\n",
    "model_list = [m for m in model_list  if 'gen' in m]\n",
    "model_list = sorted(model_list, key=lambda x: int(x[8:].split('.')[0]))\n",
    "print(model_list)\n",
    "\n",
    "G = net.Generator(config).to(device)\n",
    "G.eval()\n",
    "z = torch.FloatTensor(100, config.nz).normal_(0.0, 1.0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    old_resl = 2\n",
    "    for m in model_list:\n",
    "        resl = int(m[5])\n",
    "        if resl > old_resl:\n",
    "            G.grow_network(resl)\n",
    "            G.flush_network()\n",
    "            G.to(device)\n",
    "            G.eval()\n",
    "            old_resl = resl\n",
    "        checkpoint = torch.load(os.path.join(model_root, m))\n",
    "        G.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "#         z = torch.FloatTensor(100, config.nz).normal_(0.0, 1.0).to(device)\n",
    "        images1 = G(z[:50]).detach().cpu()\n",
    "        images2 = G(z[50:]).detach().cpu()\n",
    "        images = torch.cat((images1, images2), 0)\n",
    "        os.makedirs(save_root, exist_ok=True)\n",
    "        save_tile_images(resl, images, os.path.join(save_root, m+'.png'))\n",
    "        \n",
    "        images = None\n",
    "        for i in range(10):\n",
    "            start_ind = i*10\n",
    "            end_ind = i*10 + 9\n",
    "            zs = torch.zeros(10, config.nz).to(device)\n",
    "\n",
    "            diff = z[end_ind] - z[start_ind]\n",
    "            for j in range(9+1):\n",
    "                zs[j] = z[start_ind] + j * diff / 9\n",
    "            tmp = G(zs).detach().cpu()\n",
    "            if images is None:\n",
    "                images = tmp\n",
    "            else:\n",
    "                images = torch.cat((images, tmp), 0)\n",
    "            save_tile_images(resl, images, os.path.join(save_root, 'int_'+m+'.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpolation animation\n",
    "- 10枚\n",
    "- 遷移に20frame\n",
    "- 戻ってくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tacchan7412/Developer/pggan-pytorch/custom_layers.py:104: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if initializer == 'kaiming':    kaiming_normal(self.conv.weight, a=calculate_gain('conv2d'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing network... It may take few seconds...\n",
      "growing network[4x4 to 8x8]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[8x8 to 16x16]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[16x16 to 32x32]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[32x32 to 64x64]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[64x64 to 128x128]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[128x128 to 256x256]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "growing network[256x256 to 512x512]. It may take few seconds...\n",
      "flushing network... It may take few seconds...\n",
      "0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tacchan7412/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import network as net\n",
    "from config import config\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import utils as vutils\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "seed = 7412\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_48_14'\n",
    "# root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_48_59'\n",
    "#root = '../storage/PGGAN/results/emarie_rose/2019_10_02_15_49_29'\n",
    "\n",
    "model_root = os.path.join(root, 'models')\n",
    "\n",
    "checkpoint = torch.load(os.path.join(model_root, 'gen_R9_T950.pth.tar'))\n",
    "\n",
    "G = net.Generator(config).to(device)\n",
    "G.eval()\n",
    "z = torch.FloatTensor(100, config.nz).normal_(0.0, 1.0).to(device)\n",
    "\n",
    "resl = 9\n",
    "frame = 20\n",
    "tiles = 10\n",
    "with torch.no_grad():\n",
    "    for i in range(resl - 1):\n",
    "        G.grow_network(i+2)\n",
    "        G.flush_network()\n",
    "        G.to(device)\n",
    "        G.eval()\n",
    "    G.load_state_dict(checkpoint['state_dict'])\n",
    "#     for _ in range(10):\n",
    "#         z = torch.FloatTensor(100, config.nz).normal_(0.0, 1.0).to(device)\n",
    "    \n",
    "    images = None\n",
    "    for i in range(tiles):\n",
    "            start_ind = i % tiles\n",
    "            end_ind = (i+1) % tiles\n",
    "            print(start_ind, end_ind)\n",
    "            zs = torch.zeros(frame, config.nz).to(device)\n",
    "\n",
    "            diff = z[end_ind] - z[start_ind]\n",
    "            for j in range(frame):\n",
    "                zs[j] = z[start_ind] + j * diff / (frame-1)\n",
    "            tmp = G(zs).detach().cpu()\n",
    "            if images is None:\n",
    "                images = tmp\n",
    "            else:\n",
    "                images = torch.cat((images, tmp), 0)\n",
    "    pil_images = []\n",
    "    for im in images:\n",
    "        im = im.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "        pil_images.append(Image.fromarray(im))\n",
    "\n",
    "print(len(pil_images))\n",
    "pil_images[0].save('tmp.gif', save_all=True, append_images=pil_images[1:], optimize=False, duration=200, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
